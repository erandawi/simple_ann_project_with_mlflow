{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load the dataset\n",
    "data=pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv\", sep=\";\",)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the data into training, validation an(d test sets\n",
    "train, test = train_test_split(data, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.22</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.048</td>\n",
       "      <td>41.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.99256</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>16.85</td>\n",
       "      <td>0.054</td>\n",
       "      <td>23.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.99980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.38</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.27</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0.041</td>\n",
       "      <td>24.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.99535</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.43</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.055</td>\n",
       "      <td>18.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.99170</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.47</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.28</td>\n",
       "      <td>15.20</td>\n",
       "      <td>0.046</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.99665</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.39</td>\n",
       "      <td>10.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.52</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0.047</td>\n",
       "      <td>28.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.99418</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.32</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.039</td>\n",
       "      <td>54.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.43</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.52</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.043</td>\n",
       "      <td>28.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.99129</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.53</td>\n",
       "      <td>11.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.29</td>\n",
       "      <td>13.70</td>\n",
       "      <td>0.035</td>\n",
       "      <td>53.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.99567</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.38</td>\n",
       "      <td>10.6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.030</td>\n",
       "      <td>38.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.99255</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.63</td>\n",
       "      <td>10.4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3673 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "2835            6.3              0.25         0.22            3.30      0.048   \n",
       "1157            7.8              0.30         0.29           16.85      0.054   \n",
       "744             7.4              0.38         0.27            7.50      0.041   \n",
       "1448            7.4              0.16         0.49            1.20      0.055   \n",
       "3338            7.2              0.27         0.28           15.20      0.046   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4426            6.2              0.21         0.52            6.50      0.047   \n",
       "466             7.0              0.14         0.32            9.00      0.039   \n",
       "3092            7.6              0.27         0.52            3.20      0.043   \n",
       "3772            6.3              0.24         0.29           13.70      0.035   \n",
       "860             8.1              0.27         0.35            1.70      0.030   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "2835                 41.0                 161.0  0.99256  3.16       0.50   \n",
       "1157                 23.0                 135.0  0.99980  3.16       0.38   \n",
       "744                  24.0                 160.0  0.99535  3.17       0.43   \n",
       "1448                 18.0                 150.0  0.99170  3.23       0.47   \n",
       "3338                  6.0                  41.0  0.99665  3.17       0.39   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4426                 28.0                 123.0  0.99418  3.22       0.49   \n",
       "466                  54.0                 141.0  0.99560  3.22       0.43   \n",
       "3092                 28.0                 152.0  0.99129  3.02       0.53   \n",
       "3772                 53.0                 134.0  0.99567  3.17       0.38   \n",
       "860                  38.0                 103.0  0.99255  3.22       0.63   \n",
       "\n",
       "      alcohol  quality  \n",
       "2835     10.5        6  \n",
       "1157      9.0        6  \n",
       "744      10.0        5  \n",
       "1448     11.2        6  \n",
       "3338     10.9        6  \n",
       "...       ...      ...  \n",
       "4426      9.9        6  \n",
       "466       9.4        6  \n",
       "3092     11.4        6  \n",
       "3772     10.6        6  \n",
       "860      10.4        8  \n",
       "\n",
       "[3673 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.drop(['quality'], axis = 1).values\n",
    "train_y = train[['quality']].values.ravel()\n",
    "\n",
    "## validation dataset\n",
    "test_x = test.drop(['quality'], axis = 1).values\n",
    "test_y = test[['quality']].values.ravel()\n",
    "\n",
    "## splitting this train data into train and validation\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=0.20, random_state=42)\n",
    "\n",
    "signature = infer_signature(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANN Model\n",
    "\n",
    "def train_model(params,epochs,train_x,train_y,valid_x,valid_y,test_x,test_y):\n",
    "\n",
    "    ## Define model architecture\n",
    "    mean=np.mean(train_x,axis=0)\n",
    "    var=np.var(train_x,axis=0)\n",
    "\n",
    "    model=keras.Sequential(\n",
    "        [\n",
    "            keras.Input([train_x.shape[1]]),\n",
    "            keras.layers.Normalization(mean=mean,variance=var),\n",
    "            keras.layers.Dense(64,activation='relu'),\n",
    "            keras.layers.Dense(1)\n",
    "\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    ## compile the model\n",
    "    model.compile(optimizer=keras.optimizers.SGD(\n",
    "        learning_rate=params[\"lr\"],momentum=params[\"momentum\"]\n",
    "    ),\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "\n",
    "    ## Train the ANN model with lr and momentum params wwith MLFLOW tracking\n",
    "    with mlflow.start_run(nested=True):\n",
    "        model.fit(train_x,train_y,validation_data=(valid_x,valid_y),\n",
    "                  epochs=epochs,\n",
    "                  batch_size=64)\n",
    "        \n",
    "        ## Evaluate the model\n",
    "        eval_result=model.evaluate(valid_x,valid_y,batch_size=64)\n",
    "\n",
    "        eval_rmse=eval_result[1]\n",
    "\n",
    "        ## Log the parameters and results\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"eval_rmse\",eval_rmse)\n",
    "\n",
    "        ## log the model\n",
    "\n",
    "        mlflow.tensorflow.log_model(model,\"model\",signature=signature)\n",
    "\n",
    "        return {\"loss\": eval_rmse, \"status\": STATUS_OK, \"model\": model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective (params):\n",
    "    # MLflow will track the parameters and results for each run\n",
    "    result = train_model(\n",
    "        params,\n",
    "        epochs = 3,\n",
    "        train_x = train_x,\n",
    "        train_y = train_y,\n",
    "        valid_x = valid_x,\n",
    "        valid_y = valid_y,\n",
    "        test_x = test_x,\n",
    "        test_y = test_y,\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    \"lr\": hp.loguniform(\"lr\", np.log(1e-5), np.log(1e-1)),\n",
    "    \"momentum\": hp.uniform(\"momentum\", 0.0,1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/17 19:40:09 INFO mlflow.tracking.fluent: Experiment with name '/wine-quality' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 486ms/step - loss: 35.9030 - root_mean_squared_error: 5.9919\n",
      "\u001b[1m26/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.0576 - root_mean_squared_error: 5.0711   \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 20.4865 - root_mean_squared_error: 4.4491 - val_loss: 2.8195 - val_root_mean_squared_error: 1.6791\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 2.4973 - root_mean_squared_error: 1.5803\n",
      "\u001b[1m27/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.4040 - root_mean_squared_error: 1.5502 \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3339 - root_mean_squared_error: 1.5272 - val_loss: 1.9951 - val_root_mean_squared_error: 1.4125\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 1.3495 - root_mean_squared_error: 1.1617\n",
      "\u001b[1m23/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7736 - root_mean_squared_error: 1.3305 \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7252 - root_mean_squared_error: 1.3127\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7233 - root_mean_squared_error: 1.3120 - val_loss: 1.6417 - val_root_mean_squared_error: 1.2813\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.4200 - root_mean_squared_error: 1.1917\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6568 - root_mean_squared_error: 1.2865 \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 414ms/step - loss: 35.4326 - root_mean_squared_error: 5.9525\n",
      "\u001b[1m34/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 35.2565 - root_mean_squared_error: 5.9377   \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 35.2506 - root_mean_squared_error: 5.9372 - val_loss: 34.7294 - val_root_mean_squared_error: 5.8932\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 35.0300 - root_mean_squared_error: 5.9186\n",
      "\u001b[1m36/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34.5314 - root_mean_squared_error: 5.8762 \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34.3838 - root_mean_squared_error: 5.8636 - val_loss: 33.3285 - val_root_mean_squared_error: 5.7731\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 36.0622 - root_mean_squared_error: 6.0052\n",
      "\u001b[1m33/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 33.6635 - root_mean_squared_error: 5.8017 \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33.3627 - root_mean_squared_error: 5.7757 - val_loss: 31.9907 - val_root_mean_squared_error: 5.6560\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 31.6094 - root_mean_squared_error: 5.6222\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.6545 - root_mean_squared_error: 5.6262 \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 413ms/step - loss: 34.8318 - root_mean_squared_error: 5.9018\n",
      "\u001b[1m35/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4820 - root_mean_squared_error: 2.5644    \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6.2483 - root_mean_squared_error: 2.3251 - val_loss: 0.6990 - val_root_mean_squared_error: 0.8361\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.6682 - root_mean_squared_error: 0.8174\n",
      "\u001b[1m35/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6361 - root_mean_squared_error: 0.7975 \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6322 - root_mean_squared_error: 0.7950 - val_loss: 0.5797 - val_root_mean_squared_error: 0.7614\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.6086 - root_mean_squared_error: 0.7801\n",
      "\u001b[1m33/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5913 - root_mean_squared_error: 0.7689 \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5822 - root_mean_squared_error: 0.7629 - val_loss: 0.5468 - val_root_mean_squared_error: 0.7395\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5171 - root_mean_squared_error: 0.7191\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5403 - root_mean_squared_error: 0.7348 \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 401ms/step - loss: 33.1154 - root_mean_squared_error: 5.7546\n",
      "\u001b[1m28/46\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.3936 - root_mean_squared_error: 2.7582    \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.1497 - root_mean_squared_error: 2.3236 - val_loss: 0.5927 - val_root_mean_squared_error: 0.7699\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.7531 - root_mean_squared_error: 0.8678\n",
      "\u001b[1m40/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5870 - root_mean_squared_error: 0.7657 \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5840 - root_mean_squared_error: 0.7638 - val_loss: 0.5178 - val_root_mean_squared_error: 0.7196\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.4205 - root_mean_squared_error: 0.6485\n",
      "\u001b[1m34/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5072 - root_mean_squared_error: 0.7120 \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5105 - root_mean_squared_error: 0.7143 - val_loss: 0.5370 - val_root_mean_squared_error: 0.7328\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.4985 - root_mean_squared_error: 0.7061\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5083 - root_mean_squared_error: 0.7127 \n",
      "\n",
      "100%|██████████| 4/4 [00:47<00:00, 11.77s/trial, best loss: 0.7327852249145508]\n",
      "Best parameters : {'lr': 0.06341221281863607, 'momentum': 0.7613131184631896}\n",
      "best eval rmse: 0.7327852249145508\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"/wine-quality\")\n",
    "with mlflow.start_run():\n",
    "    # Conduct the hyperparameter search using Hyperopt\n",
    "    trials = Trials()\n",
    "    best = fmin(\n",
    "        fn = objective,\n",
    "        space = space,\n",
    "        algo = tpe.suggest,\n",
    "        max_evals=4,\n",
    "        trials = trials\n",
    "    )\n",
    "    \n",
    "    # Fetch the details of the best run\n",
    "    best_run = sorted(trials.results, key = lambda x: x[\"loss\"])[0]\n",
    "    \n",
    "    # Log the best parameters, loss, and model\n",
    "    mlflow.log_params(best)\n",
    "    mlflow.log_metric(\"eval_rmse\", best_run[\"loss\"])\n",
    "    mlflow.tensorflow.log_model(best_run[\"model\"], \"model\", signature=signature)\n",
    "    \n",
    "    # Print out the best parameters and corresponding loss\n",
    "    print(f\"Best parameters : {best}\")\n",
    "    print(f\"best eval rmse: {best_run['loss']}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 456ms/step - loss: 37.6786 - root_mean_squared_error: 6.1383\n",
      "\u001b[1m30/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.8643 - root_mean_squared_error: 6.2340   \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 38.6615 - root_mean_squared_error: 6.2177 - val_loss: 38.0897 - val_root_mean_squared_error: 6.1717\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 36.6817 - root_mean_squared_error: 6.0565\n",
      "\u001b[1m26/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 36.8908 - root_mean_squared_error: 6.0738 \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 36.9967 - root_mean_squared_error: 6.0825 - val_loss: 36.9642 - val_root_mean_squared_error: 6.0798\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 36.2871 - root_mean_squared_error: 6.0239\n",
      "\u001b[1m25/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 36.4336 - root_mean_squared_error: 6.0360 \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 36.3409 - root_mean_squared_error: 6.0283 - val_loss: 35.8773 - val_root_mean_squared_error: 5.9898\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 36.3671 - root_mean_squared_error: 6.0305\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 35.7069 - root_mean_squared_error: 5.9755 \n",
      "\n",
      "Epoch 1/3                                                                     \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 392ms/step - loss: 39.7469 - root_mean_squared_error: 6.3045\n",
      "\u001b[1m32/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 39.3403 - root_mean_squared_error: 6.2721   \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 38.8827 - root_mean_squared_error: 6.2353 - val_loss: 33.9660 - val_root_mean_squared_error: 5.8280\n",
      "\n",
      "Epoch 2/3                                                                     \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 33.3970 - root_mean_squared_error: 5.7790\n",
      "\u001b[1m36/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32.4321 - root_mean_squared_error: 5.6944 \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 32.0740 - root_mean_squared_error: 5.6627 - val_loss: 27.4594 - val_root_mean_squared_error: 5.2402\n",
      "\n",
      "Epoch 3/3                                                                     \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 29.7006 - root_mean_squared_error: 5.4498\n",
      "\u001b[1m34/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.4531 - root_mean_squared_error: 5.1425 \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.0371 - root_mean_squared_error: 5.1017 - val_loss: 22.1911 - val_root_mean_squared_error: 4.7107\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 21.2936 - root_mean_squared_error: 4.6145\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.9065 - root_mean_squared_error: 4.6804 \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 402ms/step - loss: 38.6431 - root_mean_squared_error: 6.2164\n",
      "\u001b[1m34/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0265 - root_mean_squared_error: 2.4619    \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5.7479 - root_mean_squared_error: 2.2095 - val_loss: 0.6275 - val_root_mean_squared_error: 0.7922\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.8968 - root_mean_squared_error: 0.9470\n",
      "\u001b[1m34/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6510 - root_mean_squared_error: 0.8062 \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6450 - root_mean_squared_error: 0.8026 - val_loss: 0.5534 - val_root_mean_squared_error: 0.7439\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.4145 - root_mean_squared_error: 0.6438\n",
      "\u001b[1m34/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5389 - root_mean_squared_error: 0.7338 \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5464 - root_mean_squared_error: 0.7389 - val_loss: 0.5040 - val_root_mean_squared_error: 0.7099\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.4497 - root_mean_squared_error: 0.6706\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4943 - root_mean_squared_error: 0.7029 \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 446ms/step - loss: 40.5291 - root_mean_squared_error: 6.3662\n",
      "\u001b[1m25/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.7332 - root_mean_squared_error: 6.2235   \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 38.6711 - root_mean_squared_error: 6.2185 - val_loss: 38.1010 - val_root_mean_squared_error: 6.1726\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 37.5239 - root_mean_squared_error: 6.1257\n",
      "\u001b[1m27/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 37.7674 - root_mean_squared_error: 6.1455 \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 37.6909 - root_mean_squared_error: 6.1393 - val_loss: 37.0826 - val_root_mean_squared_error: 6.0896\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 36.8368 - root_mean_squared_error: 6.0693\n",
      "\u001b[1m26/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 37.1226 - root_mean_squared_error: 6.0928 \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 36.9470 - root_mean_squared_error: 6.0784 - val_loss: 36.0948 - val_root_mean_squared_error: 6.0079\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 35.6976 - root_mean_squared_error: 5.9747\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35.7607 - root_mean_squared_error: 5.9800 \n",
      "\n",
      "100%|██████████| 4/4 [00:48<00:00, 12.22s/trial, best loss: 0.7099050879478455]\n",
      "Best parameters: {'lr': 0.06808730490522927, 'momentum': 0.4518676119309136}\n",
      "Best eval rmse: 0.7099050879478455\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"/wine-quality\")\n",
    "with mlflow.start_run():\n",
    "    # Conduct the hyperparameter search using Hyperopt\n",
    "    trials=Trials()\n",
    "    best=fmin(\n",
    "        fn=objective,\n",
    "        space=space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=4,\n",
    "        trials=trials\n",
    "    )\n",
    "\n",
    "    # Fetch the details of the best run\n",
    "    best_run = sorted(trials.results, key=lambda x: x[\"loss\"])[0]\n",
    "\n",
    "    # Log the best parameters, loss, and model\n",
    "    mlflow.log_params(best)\n",
    "    mlflow.log_metric(\"eval_rmse\", best_run[\"loss\"])\n",
    "    mlflow.tensorflow.log_model(best_run[\"model\"], \"model\", signature=signature)\n",
    "\n",
    "    # Print out the best parameters and corresponding loss\n",
    "    print(f\"Best parameters: {best}\")\n",
    "    print(f\"Best eval rmse: {best_run['loss']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.862057 ],\n",
       "       [6.8202496],\n",
       "       [6.4425383],\n",
       "       ...,\n",
       "       [6.100338 ],\n",
       "       [6.8207827],\n",
       "       [5.878961 ]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "logged_model = 'runs:/95b82f6e71e04c9d95065ba87d6edd7c/model'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "import pandas as pd\n",
    "loaded_model.predict(pd.DataFrame(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'wine-quality'.\n",
      "Created version '1' of model 'wine-quality'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1739802740217, current_stage='None', description=None, last_updated_timestamp=1739802740217, name='wine-quality', run_id='95b82f6e71e04c9d95065ba87d6edd7c', run_link=None, source='file:///c:/Users/erand/Documents/self_studies/simple_ann_project_with_mlflow/mlruns/365984032318655699/95b82f6e71e04c9d95065ba87d6edd7c/artifacts/model', status='READY', status_message=None, tags={}, user_id=None, version=1>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Register in the model registry\n",
    "mlflow.register_model(model_uri, \"wine-quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
